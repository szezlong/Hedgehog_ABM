__includes ["go_procedures//fence_behavior.nls" "go_procedures//food_behavior.nls" "go_procedures//nest_behavior.nls"]

extensions [table]

to go
  if not isEndState [
    ask hedgehogs [
      if not stay-in-nest [
        let old-position patch-here
        ifelse nest != 0 [ set distance-to-nest distance nest ] [ set distance-to-nest -1 ]
        
        update-state-variables
        
        ifelse abs (heading - last-heading) = 180 [
          set flags lput "rotated-180" flags
        ] [
          set flags remove "rotated-180" flags
        ]
        set last-heading heading
        (qlearningextension:learning true)
        
        ask patch-here [
          set visit-count visit-count + 1
        ]
        set distance-traveled distance-traveled + distance old-position
        print word "DISTANCE: " distance-traveled
      ]
    ]
    update-visited-patches
    set current-time current-time + 1
    tick
    ]
end

to update-visited-patches
  ask hedgehogs [
    let current-patch patch-here
    if not member? current-patch visited-patches [
      set visited-patches lput current-patch visited-patches
      if length visited-patches > hedgehog-memory [
        set visited-patches but-first visited-patches
      ]
    ]
  ]
end

to next-night ;;czy nie jest zbędne mając już "reset-episode"?
  while [not isEndState] [
    go
  ]
  reset-episode 
end

to face-patch [patch-to-face]
  face patch-to-face
  let angle heading
  let closest-angle first possible-angles
  let min-difference abs (closest-angle - angle)
  foreach possible-angles [ x ->
    let difference abs (x - angle)
    if difference < min-difference [
      set min-difference difference
      set closest-angle x
    ]
  ]
  set heading closest-angle
end